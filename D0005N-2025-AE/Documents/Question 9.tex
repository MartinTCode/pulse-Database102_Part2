\section{Person}
Due to confidentiality agreement with the company, the person's name and the company's name cannot be disclosed. The person is thus described as:
Anonymous data engineer (primarily working in the ETL layer). The interviewee disclosed that their educational background is a master degree in computer science.

\section{Organization}
This section profiles the organization at which the person with whom we have conducted the interview is working. 
Due to confidentiality agreement with the company, the company's name cannot be disclosed. The company is thus described as:
An international Swedish housing development company with around a thousand employees.
\section{Interview Questions}
Here is the summarized answers for the interview followed by a subchapter about our reflections on those answers. See Appendix~\ref{sec:interview} for the full transcript.
\subsection{Question 1: What is the value of data warehouse to decision making?}

In the interview a representative from a housing development company emphasized the critical role of their data platform 
in decision-making. While they use a data lakehouse rather than a traditional data warehouse, the platform provides valuable 
insights across multiple areas, including finance, health and safety, sales, and marketing.

For example, project leads access continuously updated reports to monitor cost trends, safety compliance, and project performance. 
This enables them to quickly identify cost overruns and optimize spending. Marketing teams use the platform to track campaign 
effectiveness, assessing ROI across different channels to refine their strategies. Similarly, sales teams analyze data to understand 
which projects sell quickly and which require additional effort, helping optimize pricing and marketing tactics.

Overall, the company's centralized data platform enhances operational efficiency, financial oversight, and strategic planning, 
demonstrating the importance of robust data infrastructure in modern business decision-making.
\subsubsection{Reflections on answer to question 1}
A Data Lakehouse (DLH) was mentioned in the interview, a hybrid type of warehouse that combines the benefits of both Data Lakes and Data Warehouses. 
Unlike traditional Data Warehouses (DWH), which focus on structured data, DLHs allow for a mix of structured and unstructured data, 
providing greater flexibility and real-time analytics \cite{datalakehouse}. This is especially useful for continuous decision-making, like in the housing company example. 
It would be beneficial to explore the differences between DWH and DLH further, as their differences weren't covered in the course.

The company's platform offers insights across various business areas, similar to how Data Warehouses provide insights across multiple domains in the course material. 
The platform supports decision-making in finance, health and safety, and marketing, highlighting the importance of having centralized, up-to-date data for strategic decisions. 
This aligns with the role of DWHs in consolidating data for business intelligence.

\subsection{Question 2: Which decisions you think could be supported via the data warehouse?}

In the interview it was explained how the company's data lakehouse plays a key role in decision-making. While primarily relying on 
internal data, they are actively exploring ways to integrate external market trends to enhance their analytical capabilities.

The platform allows project leads to monitor costs in real time, helping them identify overruns and adjust spending accordingly. 
Marketing teams use data insights to assess campaign performance and optimize ad placements on platforms like Google and YouTube. 
Sales teams analyze trends to determine where additional marketing efforts are needed and whether pricing strategies should be adjusted. 
Additionally, by reviewing past project success, the company refines its future investment and development strategies.

Looking ahead, they aim to incorporate broader housing market data and industry trends, which would provide a more comprehensive basis 
for strategic decision-making.
\subsubsection{Reflections on answer to question 2}

The integration of external data with internal data is mentioned as providing a richer and more holistic view, enhancing decision-making processes. 
It would be valuable to explore how such integration is implemented in data warehouses (DWH), as this could offer a deeper understanding 
of how to analyze external market trends which shape business strategies. Further investigation into the different sources and types of external data 
would be an interesting area for future study, especially in the context of DWH and business intelligence.

Real-time monitoring is a crucial feature in DWH systems \cite[p. 1230]{CourseLitt}. Observing how it is applied in practice, such as tracking project costs, 
could offer a practical example of its impact on decision-making.

The use of external data to predict future trends is a compelling aspect. By incorporating external market trends, the company can potentially 
anticipate shifts in the housing market and adjust its strategies accordingly. A deeper analysis of how external data sources contribute to forecasting 
and trend analysis would be useful for understanding its role in strategic decision-making. This could open avenues for more proactive planning, 
especially in volatile or dynamic markets.

\subsection{Question 3: What is the role of analytics sandboxes in today's business intelligence environment?} 

The representative discussed how they do not use a traditional analytics sandbox, but instead operate with flexible environments that 
serve similar functions. Their system is built on a data lakehouse, and they maintain development, test, and production environments 
to support rapid development and experimentation. These environments allow teams to test new hypotheses and analysis methods without 
affecting the production environment.

The company also uses Apache Spark and Parquet files, which enable them to conduct ad hoc analysis in a flexible, low-risk way. The 
use of Jupyter Notebooks provides the ability to test and visualize data quickly, making it possible to try out different approaches and 
gather insights without disrupting ongoing operations. This setup supports rapid development cycles and allows for fearless experimentation 
in a way that is similar to the benefits provided by an analytics sandbox.
\subsubsection{Reflections on answer to question 3}

The DLH approach offers more flexibility for experimentation compared to traditional DWH, which often limits rapid iteration \cite{datalakehouse}. 
It's interesting how DLH integrates structured and unstructured data for dynamic development cycles. It could be of interest
to learn more about the similaities and key differences between DLH and sandboxes in DWH in relation to analytics.

The use of Apache Spark and Parquet files for ad hoc analysis is intriguing. It would be beneficial to explore how these tools compare to
traditional BI tools in terms of flexibility and user experience would be beneficial. This comparison could provide insights into the advantages and limitations of each approach, helping to determine the most suitable tools for various analytical needs.
The use of Parquet files for storage means they are using a columnar storage format, which is known for its efficiency in handling large datasets \cite{apache_parquet}.
the use of Apache Spark seems to be a popular, scalable engine for big data processing with machine learning tool support \cite{apache_spark}, it would be interesting to learn more of it's core role in the Data LakeHouse environment in comparrison to the different parts of a Data Warehouse.

\subsection{Question 4: How to select an OLAP tool?}

The representative explained that their company does not use an stricly speaking OLAP tool within their data team, but instead uses a tool called Power Bi which they find sufficient for their analytical needs. 
Another team, the statistics team, does however use an OLAP tool, which name cannot be disclosed due to confidentiality agreement. 
When selecting an OLAP tool, performance is a key consideration, particularly the ability to store all data in memory rather than on disk, which 
provides significant performance benefits. However, this approach can lead to high costs due to the high and expensive memory usage.

The company is currently exploring alternatives to their existing OLAP tool, considering non-OLAP tools like Spark and Power BI for certain use cases. 
The representative noted that for their team, Spark and notebooks already fulfill many of the functionalities required for ad hoc analysis, 
offering a more flexible and cost-effective solution compared to their current traditional OLAP tool.

\subsubsection{Reflections on answer to question 4}

The use of Power BI instead of traditional OLAP tools is an interesting shift, as it highlights a more flexible and cost-effective approach
in comparison to their current OLAP tool. 
However, this raises the question of when OLAP tools become essential. They seem to be needed when the complexity of analysis or the volume 
of data requires fast, multidimensional querying \cite[p.1288]{CourseLitt} that tools like Power BI may struggle to handle.

The trade-off between performance and cost is a key insight. In-memory storage can deliver impressive performance but at a high price. 
While OLAP tools may be ideal for speed and complexity, alternatives like Spark and Power BI seem to offer a more balanced approach,
in the interviewee's organisation, 
especially when cost efficiency becomes a priority. 
It makes you think about how organizations really have to weigh the value of performance against financial limitations and 
to perhaps be restricive in their approach to when and how to implement in-memory based OLAP tools.





